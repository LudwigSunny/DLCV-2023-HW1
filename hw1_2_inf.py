# -*- coding: utf-8 -*-
"""2023dlcvhw1-2-inf.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aSuGxDZK4QPewf-fjPQSRMOeczn2iLU7

# Set up packages for HW1
"""

# Import necessary packages.
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import os
import argparse
import torchvision.transforms as transforms
import torchvision.models as models
from PIL import Image #PIL包含在pillow這個函式庫
# "ConcatDataset" and "Subset" are possibly useful when doing semi-supervised learning.
from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset
from torchvision.datasets import DatasetFolder, VisionDataset
# This is for the progress bar.
from tqdm import tqdm
import random


# 创建 ArgumentParser 对象
parser = argparse.ArgumentParser(description='Description inference.')

# 添加命令行参数
parser.add_argument('--arg1', type=str, help='Help message for arg1')
parser.add_argument('--arg2', type=str, help='Help message for arg2')
parser.add_argument('--arg3', type=str, help='Help message for arg3')

# 解析命令行参数
args = parser.parse_args()

# storing the arguments
test_img_csv = args.arg1
test_img_dir = args.arg2
output_pred_path = args.arg3
check_path = './hw1_2.ckpt'

# set a random seed for reproducibility
myseed = 6666
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
np.random.seed(myseed)
torch.manual_seed(myseed)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(myseed)

# All we need here is to resize the PIL image and transform it into Tensor.
test_tfm = transforms.Compose([
    transforms.Resize((128,128)),
    transforms.ToTensor(),
     transforms.Normalize(mean=[0.485, 0.456, 0.406],
                        std=[0.229, 0.224, 0.225]),
])

"""# Datasets"""

class hw1_2Dataset(Dataset):

    def __init__(self,path,tfm=test_tfm,files = None):
        super(hw1_2Dataset).__init__()
        self.path = path
        self.files = sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(".jpg")])
        if files != None:
            self.files = files

        self.transform = tfm

    def __len__(self):
        return len(self.files)

    def __getitem__(self,idx):
        fname = self.files[idx] # fname = ./hw1_data/p1_data/train_50/31_327.png
        im = Image.open(fname)
        im = self.transform(im)

        try:
            label = int(fname.split("/")[-1].split("_")[0])
        except:
            label = -1 # test has no label

        return im,label

"""# Create Model and Configurations"""

# "cuda" only when GPUs are available.
device = "cuda" if torch.cuda.is_available() else "cpu"

num_classes = 65

# Initialize a model, and put it on the device specified.
model_A = models.resnet50(pretrained=False)
in_features = model_A.fc.in_features
model_A.fc = torch.nn.Linear(in_features, num_classes)
model_A.load_state_dict(torch.load(check_path))

model = model_A
model.to(device)
# The number of batch size.
batch_size = 128
criterion = nn.CrossEntropyLoss()

"""# Dataloader(Office-Home)"""

office_valid_set = hw1_2Dataset(test_img_dir, tfm=test_tfm)
office_valid_loader = DataLoader(office_valid_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)

"""# Downstream task on Office-Home dataset"""

model.eval()

# These are used to record information in validation.
valid_loss = []
valid_accs = []

# Iterate the validation set by batches.
for batch in tqdm(office_valid_loader):

    # A batch consists of image data and corresponding labels.
    imgs, labels = batch
    #imgs = imgs.half()

    # We don't need gradient in validation.
    # Using torch.no_grad() accelerates the forward process.
    with torch.no_grad():
        logits = model(imgs.to(device))

    # We can still compute the loss (but not the gradient).
    loss = criterion(logits, labels.to(device))

    # Compute the accuracy for current batch.
    acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()

    # Record the loss and accuracy.
    valid_loss.append(loss.item())
    valid_accs.append(acc)
    #break

# The average loss and accuracy for entire validation set is the average of the recorded values.
valid_loss = sum(valid_loss) / len(valid_loss)
valid_acc = sum(valid_accs) / len(valid_accs)

# Print the information.
print(f"[ Valid ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}")

"""### Testing and generate prediction CSV"""

prediction = []
with torch.no_grad():
    for data,_ in tqdm(office_valid_loader):
        test_pred = model(data.to(device))
        test_pred_np = test_pred.cpu().data.numpy()

        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)
        prediction += test_label.squeeze().tolist()

#create test csv
def get_filename(test_path):
    return sorted([x for x in os.listdir(test_path) if x.endswith(".jpg")])
filename = get_filename(test_img_dir)
df = pd.DataFrame()
df["id"] = [i for i in range(len(office_valid_set))]
df["filename"] = filename
df["label"] = prediction
df.to_csv(output_pred_path, index = False)